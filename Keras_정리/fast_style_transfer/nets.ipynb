{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model,Sequential\n",
    "from layers import InputNormalize,VGGNormalize,ReflectionPadding2D,Denormalize,conv_bn_relu,res_conv,dconv_bn_nolinear\n",
    "from loss import StyleReconstructionRegularizer,FeatureReconstructionRegularizer,TVRegularizer\n",
    "from keras import backend as K\n",
    "from VGG16 import VGG16\n",
    "import img_util\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def image_transform_net(img_width,img_height,tv_weight=1):\n",
    "    x = Input(shape=(img_width,img_height,3))\n",
    "    a = InputNormalize()(x)\n",
    "    a = ReflectionPadding2D(padding=(40,40),input_shape=(img_width,img_height,3))(a)\n",
    "    a = conv_bn_relu(32, 9, 9, stride=(1,1))(a)\n",
    "    a = conv_bn_relu(64, 9, 9, stride=(2,2))(a)\n",
    "    a = conv_bn_relu(128, 3, 3, stride=(2,2))(a)\n",
    "    for i in range(5):\n",
    "        a = res_conv(128,3,3)(a)\n",
    "    a = dconv_bn_nolinear(64,3,3)(a)\n",
    "    a = dconv_bn_nolinear(32,3,3)(a)\n",
    "    a = dconv_bn_nolinear(3,9,9,stride=(1,1),activation=\"tanh\")(a)\n",
    "    # Scale output to range [0, 255] via custom Denormalize layer\n",
    "    y = Denormalize(name='transform_output')(a)\n",
    "    \n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    \n",
    "    if tv_weight > 0:\n",
    "        add_total_variation_loss(model.layers[-1],tv_weight)\n",
    "        \n",
    "    return model \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_net(x_in, trux_x_in,width, height,style_image_path,content_weight,style_weight):\n",
    "    # Append the initial input to the FastNet input to the VGG inputs\n",
    "    x = concatenate([x_in, trux_x_in], axis=0)\n",
    "    \n",
    "    # Normalize the inputs via custom VGG Normalization layer\n",
    "    x = VGGNormalize(name=\"vgg_normalize\")(x)\n",
    "\n",
    "    vgg = VGG16(include_top=False,input_tensor=x)\n",
    "\n",
    "    vgg_output_dict = dict([(layer.name, layer.output) for layer in vgg.layers[-18:]])\n",
    "    vgg_layers = dict([(layer.name, layer) for layer in vgg.layers[-18:]])\n",
    "\n",
    "    if style_weight > 0:\n",
    "        add_style_loss(vgg,style_image_path , vgg_layers, vgg_output_dict, width, height,style_weight)   \n",
    "\n",
    "    if content_weight > 0:\n",
    "        add_content_loss(vgg_layers,vgg_output_dict,content_weight)\n",
    "\n",
    "    # Freeze all VGG layers\n",
    "    for layer in vgg.layers[-19:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return vgg\n",
    "\n",
    "def add_style_loss(vgg,style_image_path,vgg_layers,vgg_output_dict,img_width, img_height,weight):\n",
    "    style_img = img_util.preprocess_image(style_image_path, img_width, img_height)\n",
    "    print('Getting style features from VGG network.')\n",
    "\n",
    "    style_layers = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']\n",
    "\n",
    "    style_layer_outputs = []\n",
    "\n",
    "    for layer in style_layers:\n",
    "        style_layer_outputs.append(vgg_output_dict[layer])\n",
    "\n",
    "    vgg_style_func = K.function([vgg.layers[-19].input], style_layer_outputs)\n",
    "\n",
    "    style_features = vgg_style_func([style_img])\n",
    "\n",
    "    # Style Reconstruction Loss\n",
    "    for i, layer_name in enumerate(style_layers):\n",
    "        layer = vgg_layers[layer_name]\n",
    "\n",
    "        feature_var = K.variable(value=style_features[i][0])\n",
    "        style_loss = StyleReconstructionRegularizer(\n",
    "                            style_feature_target=feature_var,\n",
    "                            weight=weight)(layer)\n",
    "\n",
    "        layer.add_loss(style_loss)\n",
    "\n",
    "def add_content_loss(vgg_layers,vgg_output_dict,weight):\n",
    "    # Feature Reconstruction Loss\n",
    "    content_layer = 'block3_conv3'\n",
    "    content_layer_output = vgg_output_dict[content_layer]\n",
    "\n",
    "    layer = vgg_layers[content_layer]\n",
    "    content_regularizer = FeatureReconstructionRegularizer(weight)(layer)\n",
    "    layer.add_loss(content_regularizer)\n",
    "\n",
    "\n",
    "def add_total_variation_loss(transform_output_layer,weight):\n",
    "    # Total Variation Regularization\n",
    "    layer = transform_output_layer  # Output layer\n",
    "    tv_regularizer = TVRegularizer(weight)(layer)\n",
    "    layer.add_loss(tv_regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
